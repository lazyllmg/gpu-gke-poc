apiVersion: batch/v1
kind: Job
metadata:
  name: gpu-stress
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: gpu-stress
        image: pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime
        command: ["python", "-c"]
        args:
          - |
            import torch, time
            print("CUDA available:", torch.cuda.is_available())
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            size = 4096
            a = torch.randn(size, size, device=device)
            b = torch.randn(size, size, device=device)
            start = time.time()
            elapsed = 0
            iters = 0
            while elapsed < 240:
                c = torch.mm(a, b)
                _ = c.sum().item()
                iters += 1
                elapsed = time.time() - start
                if iters % 10 == 0:
                    print(f"Iteration {iters}, elapsed {elapsed:.1f}s")
            print(f"Total iterations: {iters}")
            print("Total elapsed:", elapsed, "seconds")
        resources:
          limits:
            nvidia.com/gpu: 1
